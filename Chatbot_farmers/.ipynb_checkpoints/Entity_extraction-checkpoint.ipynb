{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Jan 29 11:30:07 2019\n",
    "\n",
    "@author: Vaishnavi Killekar\n",
    "\n",
    "This file performs all the background processing.\n",
    "The model is trained with the dataset.\n",
    "All user queries are processed here and a response is generated which is sent to the controller.\n",
    "\"\"\"\n",
    "\n",
    "class Balaram:\n",
    "\n",
    "\t\n",
    "\tdef __init__(self):\n",
    "\t\timport pandas as pd\n",
    "\t\timport numpy as np\n",
    "\t\t\n",
    "\t\tglobal pd, np\n",
    "\t\tglobal X, y\n",
    "\t\tglobal X_train, X_test, y_train, y_test, y_pred\n",
    "\t\tglobal label_map\n",
    "\t\t\n",
    "\t\tprint(\"Instance created successfully!\")\n",
    "\n",
    "\n",
    "\n",
    "\tdef setup_model(self):\n",
    "\t\t'''\n",
    "\t\tLoad the dataset and prepare it to the train the model\n",
    "\t\t'''\n",
    "\t\t# Importing dataset and splitting into words and labels\n",
    "\t\tdataset = pd.read_csv('data-tags.csv')\n",
    "\t\tX = dataset.iloc[:, :-1].values\n",
    "\t\ty = dataset.iloc[:, 1].values\n",
    "\t\tX = X.reshape(628,)\n",
    "\t\tprint(\"Dataset successfully loaded!\")\n",
    "\t\t\n",
    "\t\t# Create a bag of words model for words\n",
    "\t\tfrom sklearn.feature_extraction.text import CountVectorizer\n",
    "\t\tcv = CountVectorizer(max_features=1500)\n",
    "\t\tX = cv.fit_transform(X.astype('U')).toarray()\n",
    "\t\tprint(\"Bag of words created!\")\n",
    "\n",
    "\t\t# Save CountVectorizer state\n",
    "\t\timport pickle\n",
    "\t\tfilename = 'countVectorizer.sav'\n",
    "\t\tpickle.dump(cv, open(filename, 'wb'))\n",
    "\t\tprint(\"CountVectorizer state saved!\")\n",
    "\t\t\n",
    "\t\t# Encoding categorical data of labels\n",
    "\t\tfrom sklearn.preprocessing import LabelEncoder\n",
    "\t\tlabelencoder_y = LabelEncoder()\n",
    "\t\ty = labelencoder_y.fit_transform(y.astype(str))\n",
    "\t\tprint(\"Encoded the classes!\")\n",
    "\n",
    "\t\t# Return a dict mapping labels to their integer values\n",
    "\t\tres = {}\n",
    "\t\tfor cl in labelencoder_y.classes_:\n",
    "\t\t\tres.update({cl:labelencoder_y.transform([cl])[0]})\n",
    "\t    \n",
    "\t\tglobal label_map\n",
    "\t\tlabel_map = res\n",
    "\t\tprint(\"Label mapping obtained!\")\n",
    "\t\t\n",
    "\t\t# Fit the classifier to dataset\n",
    "\t\tfrom sklearn.naive_bayes import GaussianNB\n",
    "\t\tclassifier = GaussianNB()\n",
    "\t\tclassifier.fit(X, y)\n",
    "\t\tprint(\"Model trained successfully!\")\n",
    "\t\t\n",
    "\t\t# Save trained model state\n",
    "\t\tfilename = 'classifier.sav'\n",
    "\t\tpickle.dump(classifier, open(filename, 'wb'))\n",
    "\t\tprint(\"Trained model saved!\")\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\tdef get_entities(self, text):\n",
    "\t\t'''\n",
    "\t\tExtract entities from user text\n",
    "\t\t'''\n",
    "\t\t# Restore model state to make prediction\n",
    "\t\timport pickle\n",
    "\t\tload_cv = pickle.load(open('countVectorizer.sav', 'rb'))\n",
    "\t\ttext = load_cv.transform(text).toarray()\n",
    "# \t\tprint(\"CV loaded!\")\n",
    "\n",
    "\t\tload_classifier = pickle.load(open('classifier.sav', 'rb'))\n",
    "\t\tresponse_tags = load_classifier.predict(text)\n",
    "\n",
    "\t\tentity_list=[]\n",
    "\t\tfor tag in response_tags:\n",
    "\t\t\tif tag in label_map.values():\n",
    "\t\t\t\tentity_list.append(list(label_map.keys())[list(label_map.values()).index(tag)])\n",
    "\n",
    "\t\treturn entity_list\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\tdef generateResponse(self, text):\n",
    "\t\t'''\n",
    "\t\tGenerate response for user text\n",
    "\t\t'''\n",
    "# \t\tprint(\"Received: \", text)\n",
    "\t\t\n",
    "\t\t# Extract entities from text\n",
    "\t\tentities = self.get_entities(text);\n",
    "\t\t\n",
    "# \t\tprint(entities)\n",
    "\t\t\n",
    "\t\t# Mapping between tokens and entity tags\n",
    "\t\ttoken_entity_map=dict(zip(entities, text))\n",
    "\t\tprint(token_entity_map)\n",
    "\t\t\n",
    "\t\t# Fetch data from database based on available information provided by user\n",
    "\t\tself.fetch_data(token_entity_map)\n",
    "\n",
    "\t\t\n",
    "\tdef fetch_data(self, entity_tags):\n",
    "\t\t'''\n",
    "\t\tFetch the data from database based on received entities\n",
    "\t\t'''\n",
    "\t\t\n",
    "\t\tif \"GREET\" in entity_tags:\n",
    "\t\t\tif \"USR\" and \"INT\" in entity_tags:\n",
    "\t\t\t\tprint(\"Namaste, \"+entity_tags.get(\"NAME\")+\"!\")\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"Namaste! I'm Balaram.\")\n",
    "\t\t\t\t\n",
    "\t\telif \"WTR\" and \"TIME\" and not \"CROP\" or \"ADJ\" in entity_tags:\n",
    "\t\t\tprint(\"Weather for the asked day/week\")\n",
    "\t\t\t\t\n",
    "\t\telif \"CROP\" in entity_tags:\n",
    "\t\t\tif \"CUL\" in entity_tags:\n",
    "\t\t\t\tif \"SOIL\" in entity_tags:\n",
    "\t\t\t\t\tprint(\"Crop can be Cultivated in mentioned soil(s)\")\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tprint(\"Cultivation info along with season\")\n",
    "\t\t\t\n",
    "\t\t\telif \"IRR\" in entity_tags:\n",
    "\t\t\t\tprint(\"Irrigation info for crop\")\n",
    "\t\t\t\t\n",
    "\t\t\telif \"TIME\" in entity_tags:\n",
    "\t\t\t\tprint(\"Crop timing\")\n",
    "\t\t\t\t\n",
    "\t\t\telif \"FTLZ\" in entity_tags:\n",
    "\t\t\t\tprint(\"Fertilizer for crop\")\n",
    "\t\t\t\t\n",
    "\t\t\telif \"PEST\" in entity_tags:\n",
    "\t\t\t\tprint(\"Pesticide for crop\")\n",
    "\t\t\t\t\n",
    "\t\t\telif \"RAIN\" in  entity_tags:\n",
    "\t\t\t\tprint(\"Rainfall info for crop\")\n",
    "\t\t\t\t\n",
    "\t\t\telif \"SOIL\" in entity_tags:\n",
    "\t\t\t\tprint(\"Soil info for crop\")\n",
    "\t\t\t\t\n",
    "\t\t\telif \"WTR\" in  entity_tags:\n",
    "\t\t\t\tprint(\"Crop weather info\")\n",
    "\t\t\t\t\n",
    "\t\t\telif \"SOW\" in entity_tags:\n",
    "\t\t\t\tprint(\"Crop sowing info\")\n",
    "\t\t\t\t\n",
    "\t\t\telif \"REAP\" in entity_tags:\n",
    "\t\t\t\tprint(\"Crop reaping info\")\n",
    "\n",
    "\t\t\telif \"YLD\" in entity_tags:\n",
    "\t\t\t\tprint(\"Crop yield info\")\n",
    "\t\t\t\t\n",
    "\t\t\telif \"SEED\" and \"TYPE\" in entity_tags:\n",
    "\t\t\t\tprint(\"Crop seed info\")\n",
    "\t\t\t\t\n",
    "\t\t\telif \"COST\" in entity_tags:\n",
    "\t\t\t\tprint(\"Market price info of crop\")\t\t\n",
    "\t\t\t\t\n",
    "\t\t\telif \"QTY\" and \"MSR\" or \"SEED\" in entity_tags:\n",
    "\t\t\t\tprint(\"Seed density of crop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance created successfully!\n",
      "Dataset successfully loaded!\n",
      "Bag of words created!\n",
      "CountVectorizer state saved!\n",
      "Encoded the classes!\n",
      "Label mapping obtained!\n",
      "Model trained successfully!\n",
      "Trained model saved!\n",
      "Namaste! I am Balaram.\n",
      "Hello\n",
      "{'GREET': 'hello'}\n",
      "Namaste! I'm Balaram.\n",
      "Rainfall for rice?\n",
      "{'RAIN': 'rainfall', 'SW': 'for', 'CROP': 'rice'}\n",
      "Rainfall info for crop\n",
      "Weather today?\n",
      "{'WTR': 'weather', 'TIME': 'today'}\n"
     ]
    }
   ],
   "source": [
    "ask = Balaram()\n",
    "\n",
    "# Load data and train model\n",
    "ask.setup_model()\n",
    "\n",
    "print(\"Namaste! I am Balaram.\")\n",
    "\n",
    "def process_input(text):\n",
    "\t'''\n",
    "\tProcess the user input i.e., remove all punctuation and special symbols.\n",
    "\tTokenize the input for tagging\n",
    "\t'''\n",
    "\t# Strip text of all symbols\n",
    "\timport re\n",
    "\ttext = re.sub('[^A-Za-z]', ' ', text)\n",
    "\t\n",
    "\t# Convert text to lower\n",
    "\ttext = text.lower()\n",
    "\t\n",
    "\t# Tokenize text into individual words\n",
    "\ttext = text.split()\n",
    "\t\n",
    "\treturn text\n",
    "\n",
    "while True:\n",
    "\t# Get user input\n",
    "\ttext = input()\n",
    "\t\n",
    "\t# Process input\n",
    "\ttext = process_input(text)\n",
    "# \tprint(text)\n",
    "\t\n",
    "\t# Response generation\n",
    "\task.generateResponse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
